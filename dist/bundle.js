/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./src/audio/PhonemeSequencer.js":
/*!***************************************!*\
  !*** ./src/audio/PhonemeSequencer.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   PhonemeSequencer: () => (/* binding */ PhonemeSequencer)\n/* harmony export */ });\n/* harmony import */ var _state_phonemeMap_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../state/phonemeMap.js */ \"./src/state/phonemeMap.js\");\n\n\nclass PhonemeSequencer {\n  constructor(setParameters) {\n    this.setParameters = setParameters;\n    this.timeout = null;\n    this.sequenceTimeouts = [];\n  }\n   \n  triggerPhoneme(name) {\n    // Normalize name (strip slashes if present)\n    const key = name.replace(/\\//g, '');\n    const phoneme = _state_phonemeMap_js__WEBPACK_IMPORTED_MODULE_0__.phonemeMap[key];\n    if (!phoneme) {\n      console.warn(`Phoneme \"${name}\" not found in phonemeMap.`);\n      return;\n    }\n\n    // --- Affricate logic ---\n    if (phoneme.type === \"affricate\" && Array.isArray(phoneme.components)) {\n      const [plosiveId, fricativeId] = phoneme.components;\n      const plosive = _state_phonemeMap_js__WEBPACK_IMPORTED_MODULE_0__.phonemeMap[plosiveId];\n      const fricative = _state_phonemeMap_js__WEBPACK_IMPORTED_MODULE_0__.phonemeMap[fricativeId];\n      if (!plosive || !fricative) {\n        console.warn(`Affricate components not found for \"${name}\"`);\n        return;\n      }\n      const totalDuration = phoneme.duration ?? 0.18;\n      const plosiveDuration = totalDuration * 0.4;\n      const fricativeDuration = totalDuration * 0.6;\n\n      // Play plosive\n      this.setParameters({ ...plosive, duration: plosiveDuration });\n      if (this.timeout) clearTimeout(this.timeout);\n\n      // After plosive, play fricative\n      this.timeout = setTimeout(() => {\n        this.setParameters({ ...fricative, duration: fricativeDuration });\n        // Optionally, clear or fade out after fricative\n      }, plosiveDuration * 1000);\n      return;\n    }\n\n    // --- Default: single phoneme ---\n    this.setParameters(phoneme);\n\n    // Optionally, reset or fade out after duration\n    if (phoneme.duration) {\n      if (this.timeout) clearTimeout(this.timeout);\n      this.timeout = setTimeout(() => {\n        // Optionally: reset parameters or fade out here\n      }, phoneme.duration * 1000);\n    }\n  }\n}\n\n//# sourceURL=webpack://crowcrow/./src/audio/PhonemeSequencer.js?");

/***/ }),

/***/ "./src/audio/articulatorMapper.js":
/*!****************************************!*\
  !*** ./src/audio/articulatorMapper.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   articulatorsToZones: () => (/* binding */ articulatorsToZones)\n/* harmony export */ });\n/**\n * Maps high-level articulator parameters to 8 tract zone values.\n * @param {Object} articulators - The articulator object from phonemeMap.\n * @returns {number[]} Array of 8 zone values (0–1).\n */\nfunction articulatorsToZones(articulators) {\n  if (!articulators) return [0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5]; // fallback\n\n  // Example linear mapping (tweak as needed for realism)\n  const {\n    tongueTipX = 0.5, tongueTipY = 0.5,\n    tongueBodyX = 0.5, tongueBodyY = 0.5,\n    tongueLateral = 0,\n    lipRound = 0, lipProtrude = 0, lipClosure = 0,\n    jawHeight = 0.5,\n    velumOpen = 0,    \n  } = articulators;\n\n  // Simple illustrative mapping (customize for your model!)\n  return [\n    // zone0: lips/front\n    1 - lipClosure + 0.2 * lipRound + 0.1 * lipProtrude,\n    // zone1: alveolar ridge (tongue tip)\n    1 - tongueTipY + 0.2 * tongueTipX,\n    // zone2: post-alveolar (tongue tip/body)\n    1 - tongueTipY + 0.3 * tongueBodyX,\n    // zone3: palatal (tongue body)\n    1 - tongueBodyY + 0.2 * tongueBodyX,\n    // zone4: velar (tongue body/back)\n    1 - tongueBodyY + 0.5 * tongueBodyX,\n    // zone5: velar/uvular (tongue back)\n    1 - tongueBodyY + 0.7 * tongueBodyX,\n    // zone6: pharyngeal\n    1 - jawHeight,\n    // zone7: glottal\n    1 - jawHeight\n  ].map(v => Math.max(0, Math.min(1, v))); // clamp to [0,1]\n}\n\n\n\n//# sourceURL=webpack://crowcrow/./src/audio/articulatorMapper.js?");

/***/ }),

/***/ "./src/audio/audio-utils.js":
/*!**********************************!*\
  !*** ./src/audio/audio-utils.js ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fadeInGain: () => (/* binding */ fadeInGain),\n/* harmony export */   fadeOutGain: () => (/* binding */ fadeOutGain)\n/* harmony export */ });\n/**\n * Smoothly fades in a GainNode.\n * @param {GainNode} gainNode\n * @param {AudioContext} audioContext\n * @param {number} duration - seconds\n */\nfunction fadeInGain(gainNode, audioContext, duration = 0.05) {\n    gainNode.gain.setValueAtTime(0, audioContext.currentTime);\n    gainNode.gain.linearRampToValueAtTime(1, audioContext.currentTime + duration);\n  }\n  \n  /**\n   * Smoothly fades out a GainNode and returns a Promise that resolves after the fade.\n   * @param {GainNode} gainNode\n   * @param {AudioContext} audioContext\n   * @param {number} duration - seconds\n   * @returns {Promise<void>}\n   */\n  function fadeOutGain(gainNode, audioContext, duration = 0.5) {\n    gainNode.gain.cancelScheduledValues(audioContext.currentTime);\n    gainNode.gain.linearRampToValueAtTime(0, audioContext.currentTime + duration);\n    return new Promise(resolve => setTimeout(resolve, duration * 1000 + 20));\n  }\n\n//# sourceURL=webpack://crowcrow/./src/audio/audio-utils.js?");

/***/ }),

/***/ "./src/audio/parameterSetters.js":
/*!***************************************!*\
  !*** ./src/audio/parameterSetters.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   setParameters: () => (/* binding */ setParameters),\n/* harmony export */   updateBreathCycleRate: () => (/* binding */ updateBreathCycleRate),\n/* harmony export */   updateEffort: () => (/* binding */ updateEffort),\n/* harmony export */   updateFrequency: () => (/* binding */ updateFrequency),\n/* harmony export */   updateTenseness: () => (/* binding */ updateTenseness)\n/* harmony export */ });\nfunction updateFrequency(glottisNode, audioContext, value) {\n  if (glottisNode && audioContext && audioContext.state === 'running') {\n    const freq = parseFloat(value);\n    glottisNode.parameters.get('frequency').setValueAtTime(freq, audioContext.currentTime);\n  }\n}\n\nfunction updateTenseness(glottisNode, audioContext, value) {\n  if (glottisNode && audioContext && audioContext.state === 'running') {\n    glottisNode.parameters.get('tenseness').setValueAtTime(parseFloat(value), audioContext.currentTime);\n  }\n}\n\nfunction updateBreathCycleRate(subglottalNode, audioContext, value) {\n  if (subglottalNode && audioContext && audioContext.state === 'running') {\n    subglottalNode.parameters.get('breathCycleRate').setValueAtTime(parseFloat(value), audioContext.currentTime);\n  }\n}\n\nfunction updateEffort(subglottalNode, audioContext, value) {\n  if (subglottalNode && audioContext && audioContext.state === 'running') {\n    subglottalNode.parameters.get('effort').setValueAtTime(parseFloat(value), audioContext.currentTime);\n  }\n}\n\n\nfunction setParameters(\n  params,\n  glottisNode,\n  subglottalNode,\n  tractNode,\n  tractSliders,\n  audioContext,\n  updateParameterDisplay,\n  drawTract,\n  getZoneValuesFromSliders,\n  glideDuration = 0.04 // <-- NEW PARAM\n) {\n  // Glottis\n  if (glottisNode && glottisNode.parameters) {\n    Object.entries(params).forEach(([key, value]) => {\n      if (glottisNode.parameters.has(key)) {\n        glottisNode.parameters.get(key).setValueAtTime(value, audioContext.currentTime);\n        updateParameterDisplay(key, value);\n        const slider = document.getElementById(key + 'Slider');\n        if (slider) slider.value = value;\n      }\n    });\n  }\n  // Subglottal\n  if (subglottalNode && subglottalNode.parameters) {\n    Object.entries(params).forEach(([key, value]) => {\n      if (subglottalNode.parameters.has(key)) {\n        subglottalNode.parameters.get(key).setValueAtTime(value, audioContext.currentTime);\n        updateParameterDisplay(key, value);\n        const slider = document.getElementById(key + 'Slider');\n        if (slider) slider.value = value;\n      }\n    });\n  }\n  // Tract (zones with glide)\n  if (tractNode && tractNode.parameters && params.zones && Array.isArray(params.zones)) {\n    let tractChanged = false;\n    const now = audioContext.currentTime;\n    params.zones.forEach((value, idx) => {\n      const paramName = `zone${idx}`;\n      if (tractNode.parameters.has(paramName)) {\n        const param = tractNode.parameters.get(paramName);\n        param.cancelScheduledValues(now);\n        param.setValueAtTime(param.value, now); // start from current value\n        param.linearRampToValueAtTime(value, now + glideDuration);\n        updateParameterDisplay(paramName, value);\n        if (tractSliders && tractSliders[idx]) {\n          tractSliders[idx].value = value;\n        }\n        tractChanged = true;\n      }\n    });\n    if (tractChanged && drawTract && tractSliders) {\n      drawTract(params.zones);\n    }\n  }\n  // Tract (other parameters, set instantly)\n  ['isLateral', 'isRhotic', 'oralClosureZone', 'noiseInjectionZone', 'fricativeEffort'].forEach(key => {\n    if (tractNode && tractNode.parameters && params.hasOwnProperty(key)) {\n      tractNode.parameters.get(key).setValueAtTime(params[key], audioContext.currentTime);\n      updateParameterDisplay(key, params[key]);\n    }\n  });\n}\n\n//# sourceURL=webpack://crowcrow/./src/audio/parameterSetters.js?");

/***/ }),

/***/ "./src/main.js":
/*!*********************!*\
  !*** ./src/main.js ***!
  \*********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ui/parameterPanel.js */ \"./src/ui/parameterPanel.js\");\n/* harmony import */ var _ui_tractSliders_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ui/tractSliders.js */ \"./src/ui/tractSliders.js\");\n/* harmony import */ var _ui_tractViewer_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ui/tractViewer.js */ \"./src/ui/tractViewer.js\");\n/* harmony import */ var _ui_oscilloscope_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ui/oscilloscope.js */ \"./src/ui/oscilloscope.js\");\n/* harmony import */ var _state_parameters_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./state/parameters.js */ \"./src/state/parameters.js\");\n/* harmony import */ var _audio_audio_utils_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./audio/audio-utils.js */ \"./src/audio/audio-utils.js\");\n/* harmony import */ var _audio_parameterSetters_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./audio/parameterSetters.js */ \"./src/audio/parameterSetters.js\");\n/* harmony import */ var _audio_PhonemeSequencer_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./audio/PhonemeSequencer.js */ \"./src/audio/PhonemeSequencer.js\");\n/* harmony import */ var _state_phonemeMap_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./state/phonemeMap.js */ \"./src/state/phonemeMap.js\");\n/* harmony import */ var _ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./ui/phonemeButtonHelpers.js */ \"./src/ui/phonemeButtonHelpers.js\");\n/* harmony import */ var _audio_articulatorMapper_js__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./audio/articulatorMapper.js */ \"./src/audio/articulatorMapper.js\");\n/* harmony import */ var _ui_phonemeTypeHandlers_js__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./ui/phonemeTypeHandlers.js */ \"./src/ui/phonemeTypeHandlers.js\");\n/* harmony import */ var _state_wordPhonemeMap_js__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./state/wordPhonemeMap.js */ \"./src/state/wordPhonemeMap.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// --- Global State ---\nlet audioContext = null;\nlet noiseNode = null;\nlet subglottalNode = null;\nlet glottisNode = null;\nlet chestinessNode = null;\nlet tractNode = null;\nlet transientNode = null;\nlet nasalNode = null;\nlet analyserNode = null;\nlet isPlaying = false;\nlet gainNode = null;\nlet phonemeSequencer = null;\nlet masterGainNode = null;\nlet masterGainAnimationFrame = null;\nlet summingNode = null;\nlet currentIntensity = 1;\nlet noiseFilterNode = null;\nlet glideDuration = 0.04;\nlet clickNode = null;\nlet tapNode = null;\nlet trillNode = null;\nlet lastTractLeft = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5];\nlet lastTractRight = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5];\nconst ANALYSER_FFT_SIZE = 2048;\nconst noiseTypeMap = { white: 0, pink: 1, simplex: 2 };\n\nfunction getTractLength() {\n  const slider = document.getElementById('tractLengthSlider');\n  return slider ? parseFloat(slider.value) || 1.0 : 1.0;\n}\n\n\n\n// --- Synth Initialization ---\nasync function startSynth() {\n  if (isPlaying) return;\n  audioContext = new AudioContext();\n\n  // Load processors\n  await audioContext.audioWorklet.addModule('audio/processors/NoiseProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/SubglottalProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/GlottisProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/TransientProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/ChestinessProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/TractProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/NasalProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/SummingProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/ClickProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/TapProcessor.js');\n  await audioContext.audioWorklet.addModule('/audio/processors/TrillProcessor.js');\n\n\n  // Create nodes\n  subglottalNode = new AudioWorkletNode(audioContext, 'subglottal-processor', { outputChannelCount: [2] });\n  noiseNode = new AudioWorkletNode(audioContext, 'noise-processor');\n  glottisNode = new AudioWorkletNode(audioContext, 'glottis-processor', { numberOfInputs: 2 });\n  transientNode = new AudioWorkletNode(audioContext, 'transient-processor', { numberOfInputs: 2 });\n  chestinessNode = new AudioWorkletNode(audioContext, 'chestiness-processor');\n  tractNode = new AudioWorkletNode(audioContext, 'tract-processor', { numberOfInputs: 2 });\n  clickNode = new AudioWorkletNode(audioContext, 'click-processor');\n  tapNode = new AudioWorkletNode(audioContext, 'tap-processor');\n  trillNode = new AudioWorkletNode(audioContext, 'trill-processor');\n  noiseFilterNode = audioContext.createBiquadFilter();\n  nasalNode = new AudioWorkletNode(audioContext, 'nasal-processor');\n  summingNode = new AudioWorkletNode(audioContext, 'summing-processor', { numberOfInputs: 5, numberOfOutputs: 1 });\n  gainNode = audioContext.createGain();\n  masterGainNode = audioContext.createGain();\n  masterGainNode.gain.value = 1;\n  analyserNode = audioContext.createAnalyser();\n  analyserNode.fftSize = ANALYSER_FFT_SIZE;\n\n  console.log('AudioWorklet modules loaded & nodes created');\n\n\n  /**\n   * Audio Graph Topology:\n   *\n   *   [subglottalNode]\n   *         │\n   *   [noiseNode]─────┐\n   *         │         │\n   *     [glottisNode] │\n   *         │         │\n   *   [chestinessNode]│\n   *         │         │\n   *   [transientNode] │\n   *       │     │     │\n   *       │     └─────────────┐\n   *       │                   │\n   *   [tractNode]         [nasalNode]\n   *       │                   │\n   *       └─────┬─────┬───────┘\n   *             │     │\n   *      [clickNode]  │\n   *      [tapNode]    │\n   *      [trillNode]  │\n   *             │     │\n   *         [summingNode]\n   *               │\n   *           [gainNode]\n   *               │\n   *       [masterGainNode]\n   *               │\n   *         [analyserNode]\n   *               │\n   *   [audioContext.destination]\n   *\n   * - subglottalNode: Simulates subglottal pressure.\n   * - noiseNode: Generates noise for fricatives, aspiration, etc.\n   * - glottisNode: Simulates vocal fold vibration and voicing.\n   * - chestinessNode: Adds chest resonance.\n   * - transientNode: Handles plosive bursts and transients.\n   * - tractNode: Main vocal tract filter (8 zones, 44 segments).\n   * - nasalNode: Simulates nasal tract coupling.\n   * - clickNode/tapNode/trillNode: Special consonant bursts.\n   * - summingNode: Sums oral, nasal, click, tap, trill outputs.\n   * - gainNode/masterGainNode: Output gain control.\n   * - analyserNode: For oscilloscope/visualization.\n   */\n\n  // Audio graph connections\n  subglottalNode.connect(glottisNode);\n  noiseNode.connect(glottisNode, 0, 1);\n  glottisNode.connect(chestinessNode);\n  chestinessNode.connect(transientNode);\n  noiseNode.connect(transientNode, 0, 1);\n  transientNode.connect(tractNode);\n  transientNode.connect(nasalNode);\n  noiseNode.connect(noiseFilterNode);\n  noiseFilterNode.connect(tractNode, 0, 1);\n  tractNode.connect(summingNode, 0, 0);\n  nasalNode.connect(summingNode, 0, 1);\n  clickNode.connect(summingNode, 0, 2);\n  tapNode.connect(summingNode, 0, 3);\n  trillNode.connect(summingNode, 0, 4);\n  summingNode.connect(gainNode);\n  gainNode.connect(masterGainNode);\n  masterGainNode.connect(analyserNode);\n  analyserNode.connect(audioContext.destination);\n\n  // Fade in for smooth start\n  (0,_audio_audio_utils_js__WEBPACK_IMPORTED_MODULE_5__.fadeInGain)(masterGainNode, audioContext, 0.05);\n\n  // Set up initial chestiness node parameters\n  chestinessNode.parameters.get('chestiness').setValueAtTime(\n    parseFloat(document.getElementById('chestinessSlider').value), audioContext.currentTime\n  );// Set up analyser node\n\n  // Set initial Glottis parameters\n  _state_parameters_js__WEBPACK_IMPORTED_MODULE_4__.glottisParameterDescriptors.forEach(desc => {\n    let value = desc.defaultValue;\n    if (desc.name === 'frequency') {\n      value = parseFloat(document.getElementById('frequencySlider').value);\n    }\n    glottisNode.parameters.get(desc.name).setValueAtTime(value, audioContext.currentTime);\n  });\n\n  // Set initial Subglottal parameters\n  _state_parameters_js__WEBPACK_IMPORTED_MODULE_4__.subglottalParameterDescriptors.forEach(desc => {\n    let value = desc.defaultValue;\n    if (desc.name === 'breathCycleRate') {\n      value = parseFloat(document.getElementById('breathCycleRateSlider').value);\n    }\n    if (desc.name === 'effort') {\n      value = parseFloat(document.getElementById('effortSlider').value);\n    }\n    subglottalNode.parameters.get(desc.name).setValueAtTime(value, audioContext.currentTime);\n  });\n\n  // Receive control signals from SubglottalProcessor\n  subglottalNode.port.onmessage = (event) => {\n    const { intensity, loudness } = event.data;\n    currentIntensity = intensity;\n    if (glottisNode && audioContext && audioContext.state === 'running') {\n      glottisNode.parameters.get('intensity').setValueAtTime(intensity, audioContext.currentTime);\n      glottisNode.parameters.get('loudness').setValueAtTime(loudness, audioContext.currentTime);\n    }\n  };\n\n  // Start oscilloscope\n  const canvas = document.getElementById('oscilloscope');\n  (0,_ui_oscilloscope_js__WEBPACK_IMPORTED_MODULE_3__.drawOscilloscope)(analyserNode, canvas);\n\n  await audioContext.resume();\n  document.getElementById('startButton').textContent = 'Stop Synth';\n  isPlaying = true;\n\n  // Set up tract sliders (after tractNode is ready)\n  (0,_ui_tractSliders_js__WEBPACK_IMPORTED_MODULE_1__.setupTractSliders)(tractNode, audioContext, tractSliders);\n\n  // Set up phoneme sequencer\n  const setAllParameters = (params) => (0,_audio_parameterSetters_js__WEBPACK_IMPORTED_MODULE_6__.setParameters)(\n    params,\n    glottisNode,\n    subglottalNode,\n    tractNode,\n    tractSliders,\n    audioContext,\n    _ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay,\n    _ui_tractViewer_js__WEBPACK_IMPORTED_MODULE_2__.drawTract,\n    _ui_tractSliders_js__WEBPACK_IMPORTED_MODULE_1__.getZoneValuesFromSliders,\n    glideDuration\n  );\n  if (!phonemeSequencer) {\n    phonemeSequencer = new _audio_PhonemeSequencer_js__WEBPACK_IMPORTED_MODULE_7__.PhonemeSequencer(setAllParameters);\n  }\n}\n\n// --- Synth Teardown ---\nasync function stopSynth() {\n  if (masterGainNode && audioContext) {\n    await (0,_audio_audio_utils_js__WEBPACK_IMPORTED_MODULE_5__.fadeOutGain)(masterGainNode, audioContext, 0.3);\n  }\n  if (glottisNode) glottisNode.disconnect();\n  if (subglottalNode) subglottalNode.disconnect();\n  if (tractNode) tractNode.disconnect();\n  if (gainNode) gainNode.disconnect();\n  if (masterGainNode) masterGainNode.disconnect();\n  if (audioContext) audioContext.close();\n\n  gainNode = null;\n  masterGainNode = null;\n  glottisNode = null;\n  subglottalNode = null;\n  tractNode = null;\n  audioContext = null;\n  analyserNode = null;\n\n  document.getElementById('startButton').textContent = 'Start Synth';\n  isPlaying = false;\n}\n\n// Listener helpers ( see phonemeTypeHandlers.js for click, tap, trill handlers ) \n\n\nfunction handleRegularPhoneme(phoneme, id) {\n  // 1. Compute tract zones (asymmetric or mono)\n  let zones;\n  if (phoneme.tractLeft && phoneme.tractRight) {\n    // Visualize the average for tract viewer\n    zones = phoneme.tractLeft.map((v, i) => (v + phoneme.tractRight[i]) / 2);\n    // Set tract processor parameters\n\n\n\n    if (phoneme.tractLeft && phoneme.tractRight && tractNode && tractNode.parameters) {\n      const now = audioContext.currentTime;\n      for (let i = 0; i < 8; i++) {\n        const leftParam = tractNode.parameters.get(`tractLeft${i}`);\n        const rightParam = tractNode.parameters.get(`tractRight${i}`);\n        if (leftParam) {\n          leftParam.cancelScheduledValues(now);\n          leftParam.setValueAtTime(lastTractLeft[i], now); // start from previous\n          leftParam.linearRampToValueAtTime(phoneme.tractLeft[i], now + glideDuration);\n        }\n        if (rightParam) {\n          rightParam.cancelScheduledValues(now);\n          rightParam.setValueAtTime(lastTractRight[i], now);\n          rightParam.linearRampToValueAtTime(phoneme.tractRight[i], now + glideDuration);\n        }\n      }\n      // Update for next phoneme\n      lastTractLeft = phoneme.tractLeft.slice();\n      lastTractRight = phoneme.tractRight.slice();\n    }\n\n\n\n\n  } else if (phoneme.articulators) {\n    zones = (0,_audio_articulatorMapper_js__WEBPACK_IMPORTED_MODULE_10__.articulatorsToZones)(phoneme.articulators);\n  } else if (phoneme.zones) {\n    zones = phoneme.zones;\n  } else {\n    zones = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]; // fallback: neutral tract\n  }\n\n  // 2. Update tract visualization and UI\n  (0,_ui_tractViewer_js__WEBPACK_IMPORTED_MODULE_2__.drawTract)(zones, getTractLength());\n  (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('zones', zones.join(', '));\n  (0,_ui_tractSliders_js__WEBPACK_IMPORTED_MODULE_1__.setSlidersFromZones)(tractSliders, zones);\n  zones.forEach((value, i) => (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)(`zone${i}`, value.toFixed(2)));\n\n  // 3. Set all relevant parameters for synthesis\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setNoiseParams)(phoneme, noiseNode, noiseTypeMap, audioContext);\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setNoiseFilterParams)(phoneme, noiseFilterNode, audioContext);\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setGlottalStop)(phoneme, glottisNode, audioContext);\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setVoicedGating)(phoneme, glottisNode, audioContext, updateVoicedIndicator);\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setNasalOralControl)(phoneme, nasalNode, tractNode, audioContext);\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setLateralControl)(phoneme, tractNode, audioContext);\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setRhoticControl)(phoneme, tractNode, audioContext);\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setPlosiveBurst)(phoneme, transientNode);\n  (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.setFricativeNoiseParams)(phoneme, tractNode, currentIntensity, audioContext);\n\n  // 4. Glide duration and sequencer\n  glideDuration = (0,_ui_phonemeButtonHelpers_js__WEBPACK_IMPORTED_MODULE_9__.getEffectiveGlideDuration)(phoneme, parseFloat(document.getElementById('glideSlider').value));\n  console.log(`Setting glide duration for phoneme ${id} to ${glideDuration} seconds`);\n  phonemeSequencer.triggerPhoneme(id);\n\n  // 5. Gain gating and animation\n  if (phoneme.duration) {\n    gateMasterGain(phoneme.duration);\n    animateMasterGainSlider(phoneme.duration);\n  }\n}\n\n\n\n// --- UI Event Listeners ---\nfunction setupEventListeners() {\n\n\n  document.getElementById('glideSlider').addEventListener('input', (event) => {\n    glideDuration = parseFloat(event.target.value);\n    (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('glideDuration', glideDuration);\n    console.log(`Glide duration set to ${glideDuration} seconds`);\n  });\n\n  document.getElementById('startButton').addEventListener('click', () => {\n    isPlaying ? stopSynth() : startSynth();\n  });\n  document.getElementById('frequencySlider').addEventListener('input', (event) => {\n    (0,_audio_parameterSetters_js__WEBPACK_IMPORTED_MODULE_6__.updateFrequency)(glottisNode, audioContext, event.target.value);\n    (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('frequency', event.target.value);\n  });\n  document.getElementById('tensenessSlider').addEventListener('input', (event) => {\n    (0,_audio_parameterSetters_js__WEBPACK_IMPORTED_MODULE_6__.updateTenseness)(glottisNode, audioContext, event.target.value);\n    (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('tenseness', event.target.value);\n  });\n  document.getElementById('breathCycleRateSlider').addEventListener('input', (event) => {\n    (0,_audio_parameterSetters_js__WEBPACK_IMPORTED_MODULE_6__.updateBreathCycleRate)(subglottalNode, audioContext, event.target.value);\n    (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('breathCycleRate', event.target.value);\n  });\n  document.getElementById('effortSlider').addEventListener('input', (event) => {\n    (0,_audio_parameterSetters_js__WEBPACK_IMPORTED_MODULE_6__.updateEffort)(subglottalNode, audioContext, event.target.value);\n    (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('effort', event.target.value);\n  });\n  document.getElementById('masterGainSlider').addEventListener('input', (event) => {\n    const value = parseFloat(event.target.value);\n    if (masterGainNode) masterGainNode.gain.value = value;\n    (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('masterGain', value);\n  });\n\n  document.getElementById('tractLengthSlider').addEventListener('input', (event) => {\n    const value = parseFloat(event.target.value);\n    // Update the tract processor node if available\n    if (tractNode && tractNode.parameters && tractNode.parameters.get('tractLength')) {\n      tractNode.parameters.get('tractLength').setValueAtTime(value, audioContext.currentTime);\n      glottisNode.parameters.get('tractLength').setValueAtTime(value, audioContext.currentTime);\n    }\n    // Redraw tract with new length\n    const zones = (0,_ui_tractSliders_js__WEBPACK_IMPORTED_MODULE_1__.getZoneValuesFromSliders)(tractSliders);\n    (0,_ui_tractViewer_js__WEBPACK_IMPORTED_MODULE_2__.drawTract)(zones, value);\n\n  });\n\n  document.getElementById('chestinessSlider').addEventListener('input', (event) => {\n    const value = 1 - parseFloat(event.target.value); // reversed\n    if (chestinessNode && chestinessNode.parameters && chestinessNode.parameters.get('chestiness')) {\n      chestinessNode.parameters.get('chestiness').setValueAtTime(value, audioContext.currentTime);\n    }\n    (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('chestiness', value);\n  });\n\n\n  // --- Unified Phoneme Buttons Listener ---\n  const allPhonemeIds = [\n    // Vowels\n    'a', 'i', 'u',\n    // Plosives\n    'p', 't', 'k', 'b', 'd', 'g',\n    // Nasals\n    'm', 'n', 'ng',\n    // Approximants\n    'l', 'ɹ', 'j', 'w',\n    // Fricatives\n    'f', 'v', 's', 'z', 'sh', 'zh', 'h', 'ɦ',\n    // Specials\n    'ʔ',\n    // Affricates\n    'tʃ', 'dʒ', 'ts', 'dz',\n    // Laterals\n    'ɬ', 'ɮ',\n    // Clicks\n    'ǀ', 'ǃ', 'ǂ', 'ǁ',\n    // Taps\n    'ɾ', 'ɽ', 'ɺ',\n    // Trills\n    'r', 'ʙ', 'ʀ'\n  ];\n\n\n  allPhonemeIds.forEach(id => {\n    const btn = document.getElementById(id);\n    if (btn) {\n      btn.addEventListener('click', () => {\n        if (!isPlaying || !audioContext || !phonemeSequencer) return;\n        const phoneme = _state_phonemeMap_js__WEBPACK_IMPORTED_MODULE_8__.phonemeMap[id];\n        if (!phoneme) {\n          console.warn(`No phoneme found for id: ${id}`);\n          return;\n        }\n\n        const context = {\n          tractNode,\n          audioContext,\n          clickNode,\n          tapNode,\n          trillNode,\n          gateMasterGain,\n          animateMasterGainSlider,\n          drawTract: _ui_tractViewer_js__WEBPACK_IMPORTED_MODULE_2__.drawTract,\n          getTractLength\n        };\n\n        switch (phoneme.type) {\n          case \"click\":\n            (0,_ui_phonemeTypeHandlers_js__WEBPACK_IMPORTED_MODULE_11__.handleClickPhoneme)(phoneme, id, context);\n            break;\n          case \"tap\":\n            (0,_ui_phonemeTypeHandlers_js__WEBPACK_IMPORTED_MODULE_11__.handleTapPhoneme)(phoneme, id, context);\n            break;\n          case \"trill\":\n            (0,_ui_phonemeTypeHandlers_js__WEBPACK_IMPORTED_MODULE_11__.handleTrillPhoneme)(phoneme, id, context);\n            break;\n          default:\n            handleRegularPhoneme(phoneme, id);\n        }\n      });\n    }\n  });\n\n}\n\n// --- Tract Sliders Array ---\nconst tractSliders = [\n  document.getElementById('tractSlider0'),\n  document.getElementById('tractSlider1'),\n  document.getElementById('tractSlider2'),\n  document.getElementById('tractSlider3'),\n  document.getElementById('tractSlider4'),\n  document.getElementById('tractSlider5'),\n  document.getElementById('tractSlider6'),\n  document.getElementById('tractSlider7')\n];\n\n// --- Gain Gating and Animation ---\nfunction gateMasterGain(duration) {\n  if (!masterGainNode || !audioContext) return;\n  const now = audioContext.currentTime;\n  masterGainNode.gain.cancelScheduledValues(now);\n  masterGainNode.gain.setValueAtTime(0, now);\n  masterGainNode.gain.setValueAtTime(1, now);\n  masterGainNode.gain.linearRampToValueAtTime(0, now + duration);\n}\n\nfunction updateVoicedIndicator(isVoiced) {\n  const indicator = document.getElementById('voiced-indicator');\n  if (!indicator) return;\n  indicator.style.background = isVoiced ? '#7cff89' : '#ff7c7c';\n  indicator.title = isVoiced ? 'Voiced' : 'Unvoiced';\n}\n\n\nfunction animateMasterGainSlider(duration) {\n  const slider = document.getElementById('masterGainSlider');\n  if (!slider || !masterGainNode || !audioContext) return;\n  const start = audioContext.currentTime;\n  const end = start + duration;\n  if (masterGainAnimationFrame) {\n    cancelAnimationFrame(masterGainAnimationFrame);\n    masterGainAnimationFrame = null;\n  }\n  slider.value = 1;\n  (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('masterGain', 1);\n  function update() {\n    if (!audioContext || !masterGainNode) return;\n    const now = audioContext.currentTime;\n    let value = 1;\n    if (now >= end) {\n      value = 0;\n    } else if (now > start) {\n      value = 1 - ((now - start) / duration);\n    }\n    slider.value = value;\n    (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('masterGain', value);\n    if (now < end && value > 0.001) {\n      masterGainAnimationFrame = requestAnimationFrame(update);\n    } else {\n      slider.value = 0;\n      (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('masterGain', 0);\n      masterGainAnimationFrame = null;\n    }\n  }\n  update();\n}\n\nfunction playFromText(input, spacing = 0.02) {\n  let phonemeString = _state_wordPhonemeMap_js__WEBPACK_IMPORTED_MODULE_12__.wordPhonemeMap[input.toLowerCase()] || input;\n  const tokens = phonemeString.trim().split(/\\s+/);\n  console.log('Sequencing:', tokens);\n\n  let time = 0;\n  tokens.forEach((token, i) => {\n    const phoneme = _state_phonemeMap_js__WEBPACK_IMPORTED_MODULE_8__.phonemeMap[token.replace(/\\//g, '')];\n    if (!phoneme) {\n      console.warn(`Phoneme \"${token}\" not found in phonemeMap.`);\n      return;\n    }\n    setTimeout(() => {\n      const context = {\n        tractNode,\n        audioContext,\n        clickNode,\n        tapNode,\n        trillNode,\n        gateMasterGain,\n        animateMasterGainSlider,\n        drawTract: _ui_tractViewer_js__WEBPACK_IMPORTED_MODULE_2__.drawTract,\n        getTractLength\n      };\n      switch (phoneme.type) {\n        case \"click\":\n          (0,_ui_phonemeTypeHandlers_js__WEBPACK_IMPORTED_MODULE_11__.handleClickPhoneme)(phoneme, token, context);\n          break;\n        case \"tap\":\n          (0,_ui_phonemeTypeHandlers_js__WEBPACK_IMPORTED_MODULE_11__.handleTapPhoneme)(phoneme, token, context);\n          break;\n        case \"trill\":\n          (0,_ui_phonemeTypeHandlers_js__WEBPACK_IMPORTED_MODULE_11__.handleTrillPhoneme)(phoneme, token, context);\n          break;\n        default:\n          handleRegularPhoneme(phoneme, token);\n      }\n    }, time * 1000);\n    const duration = phoneme.duration || 0.15;\n    time += duration + spacing;\n  });\n}\n\n\nfunction setupWordPhonemeInputListener() {\n  const playBtn = document.getElementById('playWordPhonemeBtn');\n  const inputBox = document.getElementById('wordPhonemeInput');\n  if (playBtn && inputBox) {\n    playBtn.addEventListener('click', () => {\n      const input = inputBox.value.trim();\n      if (input.length > 0) {\n        console.log('[Word/Phoneme Play] Input:', input);\n        playFromText(input);\n        // Future: pass to sequencer or lookup map\n      }\n    });\n    // Optional: allow pressing Enter to trigger play\n    inputBox.addEventListener('keydown', (e) => {\n      if (e.key === 'Enter') playBtn.click();\n    });\n  }\n}\n\n// --- UI Initialization ---\ndocument.addEventListener('DOMContentLoaded', () => {\n  (0,_ui_tractSliders_js__WEBPACK_IMPORTED_MODULE_1__.setupTractSliders)(null, null, tractSliders);\n  setupEventListeners();\n  setupWordPhonemeInputListener();\n  const defaultTractRadii = _state_parameters_js__WEBPACK_IMPORTED_MODULE_4__.tractParameterDescriptors.map(desc => desc.defaultValue);\n  (0,_ui_tractViewer_js__WEBPACK_IMPORTED_MODULE_2__.drawTract)(defaultTractRadii, getTractLength());\n  (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.renderParameterList)(_state_parameters_js__WEBPACK_IMPORTED_MODULE_4__.glottisParameterDescriptors, _state_parameters_js__WEBPACK_IMPORTED_MODULE_4__.subglottalParameterDescriptors, _state_parameters_js__WEBPACK_IMPORTED_MODULE_4__.tractParameterDescriptors);\n  (0,_ui_parameterPanel_js__WEBPACK_IMPORTED_MODULE_0__.updateParameterDisplay)('masterGain', document.getElementById('masterGainSlider').value);\n});\n\n//# sourceURL=webpack://crowcrow/./src/main.js?");

/***/ }),

/***/ "./src/state/parameters.js":
/*!*********************************!*\
  !*** ./src/state/parameters.js ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   glottisParameterDescriptors: () => (/* binding */ glottisParameterDescriptors),\n/* harmony export */   subglottalParameterDescriptors: () => (/* binding */ subglottalParameterDescriptors),\n/* harmony export */   tractParameterDescriptors: () => (/* binding */ tractParameterDescriptors)\n/* harmony export */ });\n// NOTE: These parameter descriptors must be kept in sync manually with the\n// corresponding parameterDescriptors in GlottisProcessor.js, SubglottalProcessor.js, etc.\n// Changes here do NOT automatically update the processor defaults.\n\n// parameters.js\nconst glottisParameterDescriptors = [\n  { name: 'frequency', defaultValue: 120, minValue: 50, maxValue: 400, automationRate: 'a-rate' },\n  { name: 'tenseness', defaultValue: 0.6, minValue: 0, maxValue: 1, automationRate: 'a-rate' }\n];\n\nconst subglottalParameterDescriptors = [\n  { name: 'breathCycleRate', defaultValue: 0.2, minValue: 0.05, maxValue: 1.0, automationRate: 'a-rate' },\n  { name: 'effort', defaultValue: 0.8, minValue: 0, maxValue: 1, automationRate: 'a-rate' }\n];\n\nconst tractParameterDescriptors = [\n  { name: 'zone0', defaultValue: 0.5, minValue: 0, maxValue: 1, automationRate: 'k-rate' },\n  { name: 'zone1', defaultValue: 0.5, minValue: 0, maxValue: 1, automationRate: 'k-rate' },\n  { name: 'zone2', defaultValue: 0.5, minValue: 0, maxValue: 1, automationRate: 'k-rate' },\n  { name: 'zone3', defaultValue: 0.5, minValue: 0, maxValue: 1, automationRate: 'k-rate' },\n  { name: 'zone4', defaultValue: 0.5, minValue: 0, maxValue: 1, automationRate: 'k-rate' },\n  { name: 'zone5', defaultValue: 0.5, minValue: 0, maxValue: 1, automationRate: 'k-rate' },\n  { name: 'zone6', defaultValue: 0.5, minValue: 0, maxValue: 1, automationRate: 'k-rate' },\n  { name: 'zone7', defaultValue: 0.5, minValue: 0, maxValue: 1, automationRate: 'k-rate' }\n];\n\n//# sourceURL=webpack://crowcrow/./src/state/parameters.js?");

/***/ }),

/***/ "./src/state/phonemeMap.js":
/*!*********************************!*\
  !*** ./src/state/phonemeMap.js ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   phonemeMap: () => (/* binding */ phonemeMap)\n/* harmony export */ });\n/**\n * PhonemeMap: Articulator-Based Abstraction\n *\n * This file defines all phonemes using high-level articulator parameters\n * (tongue, lips, velum, etc.) instead of the legacy \"zones\" system.\n * The articulators object for each phoneme is mapped directly to the vocal tract\n * shape (44 segments) for synthesis. The \"zones\" abstraction has been removed\n * for clarity, maintainability, and directness.\n *\n * If you are extending or modifying this file, use the articulators object\n * for all new phonemes. See the project README for more details.\n *\n * Legacy note: Previously, phonemes could be defined with a \"zones\" array, e.g.:\n *   zones: [0, 0, 0.2, 0.8, 1, 0.8, 0.2, 0, 0, ...]\n * This approach is now deprecated in favor of articulator-based definitions.\n */\n\nconst phonemeMap = {\n  a: {\n    symbol: \"a\",\n    type: \"vowel\",\n    frequency: 130,\n    tenseness: 0.6,\n    effort: 0.7,\n    duration: 0.3,\n    voiced: true,\n    articulators: {\n      tongueTipX: 0.5,    // mid\n      tongueTipY: 0.2,    // low\n      tongueBodyX: 0.5,   // mid\n      tongueBodyY: 0.2,   // low\n      tongueLateral: 0,   // not lateral\n      lipRound: 0.1,      // unrounded\n      lipProtrude: 0.1,   // neutral\n      lipClosure: 0,      // open\n      jawHeight: 1.0,     // open jaw\n      velumOpen: 0,       // oral\n      tractLength: 1.0    // default\n    }\n  },\n\n  i: {\n    symbol: \"i\",\n    type: \"vowel\",\n    frequency: 200,\n    tenseness: 0.8,\n    effort: 0.5,\n    duration: 0.25,\n    voiced: true,\n    articulators: {\n      tongueTipX: 0.2,    // front\n      tongueTipY: 0.9,    // high\n      tongueBodyX: 0.2,   // front\n      tongueBodyY: 0.9,   // high\n      tongueLateral: 0,\n      lipRound: 0.0,      // unrounded\n      lipProtrude: 0.0,   // not protruded\n      lipClosure: 0,\n      jawHeight: 0.3,     // fairly closed\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  u: {\n    symbol: \"u\",\n    type: \"vowel\",\n    frequency: 160,\n    tenseness: 0.5,\n    effort: 0.6,\n    duration: 0.3,\n    voiced: true,\n    articulators: {\n      tongueTipX: 0.8,    // back\n      tongueTipY: 0.8,    // high\n      tongueBodyX: 0.8,   // back\n      tongueBodyY: 0.8,   // high\n      tongueLateral: 0,\n      lipRound: 1.0,      // fully rounded\n      lipProtrude: 0.8,   // strongly protruded\n      lipClosure: 0,\n      jawHeight: 0.3,     // fairly closed\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  p: {\n    symbol: \"p\",\n    type: \"plosive\",\n    frequency: 0,\n    tenseness: 0.4,\n    effort: 0.8,\n    duration: 0.15,\n    isPlosive: true,\n    noiseType: \"white\",\n    noiseInjectionZone: 0, // labial\n    burstDuration: 0.03,      // 30ms\n    burstSharpness: 0.8,      // fairly sharp\n    burstGain: 1.0,\n    oralClosureZone: 0,\n    voiced: false,\n    articulators: {\n      tongueTipX: 0.0,    // lips\n      tongueTipY: 0.5,    // neutral\n      tongueBodyX: 0.0,   // lips\n      tongueBodyY: 0.5,   // neutral\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.2,\n      lipClosure: 1.0,    // closed lips\n      jawHeight: 0.2,     // closed jaw\n      velumOpen: 0,       // oral\n      tractLength: 1.0\n    }\n  },\n\n  t: {\n    symbol: \"t\",\n    type: \"plosive\",\n    frequency: 0,\n    tenseness: 0.5,\n    effort: 0.8,\n    duration: 0.14,\n    isPlosive: true,\n    noiseType: \"white\",\n    noiseInjectionZone: 2, // alveolar\n    burstDuration: 0.025,     // slightly shorter\n    burstSharpness: 0.9,      // very sharp\n    burstGain: 1.1,\n    oralClosureZone: 2,\n    voiced: false,\n    articulators: {\n      tongueTipX: 0.3,    // alveolar ridge\n      tongueTipY: 0.9,    // high\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  k: {\n    symbol: \"k\",\n    type: \"plosive\",\n    frequency: 0,\n    tenseness: 0.5,\n    effort: 0.9,\n    duration: 0.16,\n    isPlosive: true,\n    noiseType: \"white\",\n    noiseInjectionZone: 5, // velar\n    burstDuration: 0.035,     // slightly longer\n    burstSharpness: 0.7,      // less sharp\n    burstGain: 1.2,\n    oralClosureZone: 5, // tongue back/velar    \n    voiced: false,\n    articulators: {\n      tongueTipX: 0.8,    // back\n      tongueTipY: 0.5,    // neutral\n      tongueBodyX: 0.8,   // back\n      tongueBodyY: 0.9,   // high\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  g: {\n    symbol: \"g\",\n    type: \"plosive\",\n    frequency: 120,\n    tenseness: 0.6,\n    effort: 0.85,\n    duration: 0.15,\n    isPlosive: true,\n    noiseType: \"pink\",\n    noiseInjectionZone: 5, // velar \n    burstDuration: 0.035,\n    burstSharpness: 0.7,\n    burstGain: 1.2,\n    oralClosureZone: 5, // tongue rear/velar    \n    voiced: true,\n    articulators: {\n      tongueTipX: 0.8,\n      tongueTipY: 0.5,\n      tongueBodyX: 0.8,\n      tongueBodyY: 0.9,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  b: {\n    symbol: \"b\",\n    type: \"plosive\",\n    frequency: 120,\n    tenseness: 0.6,\n    effort: 0.85,\n    duration: 0.15,\n    isPlosive: true,\n    noiseType: \"pink\",\n    noiseInjectionZone: 0, // labial\n    burstDuration: 0.03,\n    burstSharpness: 0.8,\n    burstGain: 1.0,\n    oralClosureZone: 0,\n    voiced: true,\n    articulators: {\n      tongueTipX: 0.0,\n      tongueTipY: 0.5,\n      tongueBodyX: 0.0,\n      tongueBodyY: 0.5,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.2,\n      lipClosure: 1.0,\n      jawHeight: 0.2,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  d: {\n    symbol: \"d\",\n    type: \"plosive\",\n    frequency: 120,\n    tenseness: 0.6,\n    effort: 0.85,\n    duration: 0.15,\n    isPlosive: true,\n    noiseType: \"pink\",\n    noiseInjectionZone: 2, // alveolar ridge\n    burstDuration: 0.025,\n    burstSharpness: 0.9,\n    burstGain: 1.1,\n    oralClosureZone: 2, // tongue tip/alveolar    \n    voiced: true,\n    articulators: {\n      tongueTipX: 0.3,\n      tongueTipY: 0.9,\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  m: {\n    symbol: \"m\",\n    type: \"nasal\",\n    frequency: 110,\n    tenseness: 0.5,\n    effort: 0.7,\n    duration: 0.25,\n    isNasal: true,\n    nasalCoupling: 1.0,          // full nasal flow (0–1)\n    oralClosureZone: 0,          // front (lips)    \n    voiced: true,\n    articulators: {\n      tongueTipX: 0.0,    // lips\n      tongueTipY: 0.5,    // neutral\n      tongueBodyX: 0.0,   // lips\n      tongueBodyY: 0.5,   // neutral\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.2,\n      lipClosure: 1.0,    // closed lips\n      jawHeight: 0.2,     // closed jaw\n      velumOpen: 1.0,     // nasal\n      tractLength: 1.0\n    }\n  },\n\n  n: {\n    symbol: \"n\",\n    type: \"nasal\",\n    frequency: 120,\n    tenseness: 0.6,\n    effort: 0.6,\n    duration: 0.2,\n    isNasal: true,\n    nasalCoupling: 1.0,\n    oralClosureZone: 2,          // mid (alveolar ridge)    \n    voiced: true,\n    articulators: {\n      tongueTipX: 0.3,    // alveolar ridge\n      tongueTipY: 0.9,    // high\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 1.0,     // nasal\n      tractLength: 1.0\n    }\n  },\n\n  ng: {\n    symbol: \"ŋ\",\n    type: \"nasal\",\n    frequency: 100,\n    tenseness: 0.5,\n    effort: 0.65,\n    duration: 0.3,\n    isNasal: true,\n    nasalCoupling: 1.0,\n    oralClosureZone: 5,          // back (velar region)    \n    voiced: true,\n    articulators: {\n      tongueTipX: 0.8,    // back\n      tongueTipY: 0.5,    // neutral\n      tongueBodyX: 0.8,   // back\n      tongueBodyY: 0.9,   // high\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 1.0,     // nasal\n      tractLength: 1.0\n    }\n  },\n  l: {\n    symbol: \"l\",\n    type: \"approximant\",\n    frequency: 120,\n    tenseness: 0.5,\n    effort: 0.6,\n    duration: 0.2,\n    isApproximant: true,\n    isLateral: true,\n    oralClosureZone: 2, // tongue tip/alveolar    \n    voiced: true,\n    tractLeft: [1, 1, 1, 0.2, 0.5, 0.5, 0.5, 0.5],\n    tractRight: [1, 1, 1, 0.2, 0.5, 0.5, 0.5, 0.5],\n    articulators: {\n      tongueTipX: 0.3,    // alveolar ridge\n      tongueTipY: 0.9,    // high\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 1.0, // full lateral airflow\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.4,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  ɹ: {\n    symbol: \"ɹ\",\n    type: \"approximant\",\n    frequency: 120,\n    tenseness: 0.5,\n    effort: 0.6,\n    duration: 0.2,\n    isApproximant: true,\n    isRhotic: true,\n    voiced: true,\n    articulators: {\n      tongueTipX: 0.4,    // postalveolar/retroflex\n      tongueTipY: 0.7,    // slightly raised\n      tongueBodyX: 0.5,\n      tongueBodyY: 0.6,\n      tongueLateral: 0.2, // slight lateral airflow\n      lipRound: 0.1,\n      lipProtrude: 0.1,\n      lipClosure: 0.0,\n      jawHeight: 0.5,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  j: {\n    symbol: \"j\",\n    type: \"approximant\",\n    frequency: 200,\n    tenseness: 0.5,\n    effort: 0.5,\n    duration: 0.2,\n    isApproximant: true,\n    glideDuration: 0.08,\n    voiced: true,\n    articulators: {\n      tongueTipX: 0.2,    // front\n      tongueTipY: 0.9,    // high\n      tongueBodyX: 0.2,   // front\n      tongueBodyY: 0.9,   // high\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  w: {\n    symbol: \"w\",\n    type: \"approximant\",\n    frequency: 120,\n    tenseness: 0.5,\n    effort: 0.5,\n    duration: 0.2,\n    isApproximant: true,\n    glideDuration: 0.09,\n    voiced: true,\n    articulators: {\n      tongueTipX: 0.8,    // back\n      tongueTipY: 0.8,    // high\n      tongueBodyX: 0.8,   // back\n      tongueBodyY: 0.8,   // high\n      tongueLateral: 0,\n      lipRound: 1.0,      // fully rounded\n      lipProtrude: 0.8,   // strongly protruded\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  f: {\n    symbol: \"f\",\n    type: \"fricative\",\n    frequency: 0,\n    tenseness: 0.5,\n    effort: 0.7,\n    duration: 0.18,\n    noiseType: \"white\",\n    noiseInjectionZone: 0, // labiodental/front        \n    voiced: false,\n    filterType: \"highpass\",\n    filterFrequency: 4000,\n    filterQ: 6,\n    articulators: {\n      tongueTipX: 0.1,    // near front\n      tongueTipY: 0.5,    // neutral\n      tongueBodyX: 0.1,\n      tongueBodyY: 0.5,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.2,\n      lipClosure: 0.5,    // partial closure (labiodental)\n      jawHeight: 0.4,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  v: {\n    symbol: \"v\",\n    type: \"fricative\",\n    frequency: 120,\n    tenseness: 0.5,\n    effort: 0.7,\n    duration: 0.18,\n    noiseType: \"pink\",\n    noiseInjectionZone: 0, // labiodental/front    \n    voiced: true,\n    filterType: \"bandpass\",\n    filterFrequency: 1500,\n    filterQ: 4,\n    articulators: {\n      tongueTipX: 0.1,\n      tongueTipY: 0.5,\n      tongueBodyX: 0.1,\n      tongueBodyY: 0.5,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.2,\n      lipClosure: 0.5,\n      jawHeight: 0.4,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  s: {\n    symbol: \"s\",\n    type: \"fricative\",\n    frequency: 0,\n    tenseness: 0.7,\n    effort: 0.8,\n    duration: 0.16,\n    noiseType: \"white\",\n    noiseInjectionZone: 2, // alveolar        \n    voiced: false,\n    filterType: \"highpass\",\n    filterFrequency: 6000,\n    filterQ: 8,\n    articulators: {\n      tongueTipX: 0.3,    // alveolar\n      tongueTipY: 0.9,    // high\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  z: {\n    symbol: \"z\",\n    type: \"fricative\",\n    frequency: 120,\n    tenseness: 0.7,\n    effort: 0.8,\n    duration: 0.16,\n    noiseType: \"pink\",\n    noiseInjectionZone: 2, // alveolar    \n    voiced: true,\n    filterType: \"highpass\",\n    filterFrequency: 6000,\n    filterQ: 8,\n    articulators: {\n      tongueTipX: 0.3,\n      tongueTipY: 0.9,\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  sh: {\n    symbol: \"ʃ\",\n    type: \"fricative\",\n    frequency: 0,\n    tenseness: 0.6,\n    effort: 0.8,\n    duration: 0.18,\n    noiseType: \"white\",\n    noiseInjectionZone: 3, // postalveolar        \n    voiced: false,\n    filterType: \"bandpass\",\n    filterFrequency: 2500,\n    filterQ: 5,\n    articulators: {\n      tongueTipX: 0.4,    // postalveolar\n      tongueTipY: 0.8,    // high\n      tongueBodyX: 0.4,\n      tongueBodyY: 0.8,\n      tongueLateral: 0,\n      lipRound: 0.1,\n      lipProtrude: 0.1,\n      lipClosure: 0.0,\n      jawHeight: 0.4,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  zh: {\n    symbol: \"ʒ\",\n    type: \"fricative\",\n    frequency: 120,\n    tenseness: 0.6,\n    effort: 0.8,\n    duration: 0.18,\n    noiseType: \"pink\",\n    noiseInjectionZone: 3, // postalveolar        \n    voiced: true,\n    filterType: \"bandpass\",\n    filterFrequency: 2000,\n    filterQ: 5,\n    articulators: {\n      tongueTipX: 0.4,\n      tongueTipY: 0.8,\n      tongueBodyX: 0.4,\n      tongueBodyY: 0.8,\n      tongueLateral: 0,\n      lipRound: 0.1,\n      lipProtrude: 0.1,\n      lipClosure: 0.0,\n      jawHeight: 0.4,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  h: {\n    symbol: \"h\",\n    type: \"fricative\",\n    frequency: 0,\n    tenseness: 0.5,\n    effort: 0.7,\n    duration: 0.15,\n    noiseType: \"simplex\",\n    noiseInjectionZone: 7, // glottal (end of tract)     \n    voiced: false, // <-- standard voiceless /h/\n    filterType: \"lowpass\",\n    filterFrequency: 3000,\n    filterQ: 1,\n    articulators: {\n      tongueTipX: 0.5,    // neutral\n      tongueTipY: 0.5,\n      tongueBodyX: 0.5,\n      tongueBodyY: 0.5,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.5,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  ɦ: {\n    symbol: \"ɦ\",\n    type: \"fricative\",\n    frequency: 120,\n    tenseness: 0.5,\n    effort: 0.7,\n    duration: 0.15,\n    noiseType: \"simplex\",\n    noiseInjectionZone: 7, // glottal (end of tract)    \n    voiced: true, // <-- voiced glottal fricative\n    filterType: \"lowpass\",\n    filterFrequency: 3000,\n    filterQ: 1,\n    articulators: {\n      tongueTipX: 0.5,\n      tongueTipY: 0.5,\n      tongueBodyX: 0.5,\n      tongueBodyY: 0.5,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.5,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  ʔ: {\n    symbol: \"ʔ\",\n    type: \"glottal_stop\",\n    frequency: 0,\n    tenseness: 1.0,\n    effort: 1.0,\n    duration: 0.08, // typical glottal stop is short\n    voiced: false,\n    glottalClosure: 1.0 // custom parameter to indicate full closure\n  },\n  tʃ: {\n    symbol: \"tʃ\",\n    type: \"affricate\",\n    components: [\"t\", \"sh\"], // plosive, then fricative\n    duration: 0.18, // total duration in seconds\n    articulators: {\n      tongueTipX: 0.35,    // postalveolar\n      tongueTipY: 0.85,\n      tongueBodyX: 0.35,\n      tongueBodyY: 0.8,\n      tongueLateral: 0,\n      lipRound: 0.1,\n      lipProtrude: 0.1,\n      lipClosure: 0.0,\n      jawHeight: 0.35,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  dʒ: {\n    symbol: \"dʒ\",\n    type: \"affricate\",\n    components: [\"d\", \"zh\"],\n    duration: 0.18,\n    articulators: {\n      tongueTipX: 0.35,    // postalveolar\n      tongueTipY: 0.85,\n      tongueBodyX: 0.35,\n      tongueBodyY: 0.8,\n      tongueLateral: 0,\n      lipRound: 0.1,\n      lipProtrude: 0.1,\n      lipClosure: 0.0,\n      jawHeight: 0.35,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  ts: {\n    symbol: \"ts\",\n    type: \"affricate\",\n    components: [\"t\", \"s\"],\n    duration: 0.16,\n    articulators: {\n      tongueTipX: 0.3,    // alveolar\n      tongueTipY: 0.9,\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  dz: {\n    symbol: \"dz\",\n    type: \"affricate\",\n    components: [\"d\", \"z\"],\n    duration: 0.16,\n    articulators: {\n      tongueTipX: 0.3,    // alveolar\n      tongueTipY: 0.9,\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 0,\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.3,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  ɬ: {\n    symbol: \"ɬ\",\n    type: \"fricative\",\n    frequency: 0,\n    tenseness: 0.7,\n    effort: 0.8,\n    duration: 0.18,\n    isLateral: true,\n    noiseType: \"white\",\n    noiseInjectionZone: 2, // alveolar    \n    voiced: false,\n    filterType: \"bandpass\",\n    filterFrequency: 4000,\n    filterQ: 7,\n    tractLeft: [1, 1, 0.7, 0.2, 0.5, 0.5, 0.5, 0.5], // partial closure at alveolar\n    tractRight: [1, 1, 0.7, 0.2, 0.5, 0.5, 0.5, 0.5],\n    articulators: {\n      tongueTipX: 0.3,    // alveolar\n      tongueTipY: 0.9,\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 1.0, // full lateral airflow\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.4,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n\n  ɮ: {\n    symbol: \"ɮ\",\n    type: \"fricative\",\n    frequency: 120,\n    tenseness: 0.7,\n    effort: 0.8,\n    duration: 0.18,\n    isLateral: true,\n    noiseType: \"pink\",\n    noiseInjectionZone: 2, // alveolar    \n    voiced: true,\n    filterType: \"bandpass\",\n    filterFrequency: 3000,\n    filterQ: 7,\n    tractLeft: [1, 1, 0.7, 0.2, 0.5, 0.5, 0.5, 0.5],\n    tractRight: [1, 1, 0.7, 0.2, 0.5, 0.5, 0.5, 0.5],\n    articulators: {\n      tongueTipX: 0.3,    // alveolar\n      tongueTipY: 0.9,\n      tongueBodyX: 0.3,\n      tongueBodyY: 0.7,\n      tongueLateral: 1.0, // full lateral airflow\n      lipRound: 0.0,\n      lipProtrude: 0.0,\n      lipClosure: 0.0,\n      jawHeight: 0.4,\n      velumOpen: 0,\n      tractLength: 1.0\n    }\n  },\n  \"ǀ\": {\n    symbol: \"ǀ\",\n    type: \"click\",\n    duration: 0.12,\n    burstZone: 1,         // where to inject the burst (tract zone index)\n    burstDuration: 0.018, // seconds\n    burstSharpness: 0.95, // envelope sharpness\n    burstGain: 1.2,       // amplitude\n    clickType: 0,         // (optional) for future: 0=dental, 1=alveolar, etc.\n    voiced: false\n  },\n\n  \"ǃ\": {\n    symbol: \"ǃ\",\n    type: \"click\",\n    duration: 0.12,\n    burstZone: 2,\n    burstDuration: 0.018,\n    burstSharpness: 0.95,\n    burstGain: 1.2,\n    clickType: 1,\n    voiced: false\n  },\n\n  \"ǂ\": {\n    symbol: \"ǂ\",\n    type: \"click\",\n    duration: 0.12,\n    burstZone: 3,\n    burstDuration: 0.018,\n    burstSharpness: 0.95,\n    burstGain: 1.2,\n    clickType: 2,\n    voiced: false\n  },\n\n  \"ǁ\": {\n    symbol: \"ǁ\",\n    type: \"click\",\n    duration: 0.13,\n    burstZone: 3, // lateral burst (postalveolar/palatal)\n    burstDuration: 0.018,\n    burstSharpness: 0.95,\n    burstGain: 1.3,\n    clickType: 3, // 3 = lateral\n    voiced: false,\n    tractLeft: [1, 1, 0, 0, 1, 1, 1, 1], // closure at lateral zones (2,3)\n    tractRight: [1, 1, 1, 0, 0, 1, 1, 1]  // closure at lateral zones (3,4)\n  },\n\n\n  // Taps\n  \"ɾ\": {\n    symbol: \"ɾ\",\n    type: \"tap\",\n    tapZone: 2,           // alveolar\n    tapDuration: 0.025,   // seconds\n    tapGain: 0.5,\n    duration: 0.05,       // for envelope/gating\n    voiced: true\n  },\n  \"ɽ\": {\n    symbol: \"ɽ\",\n    type: \"tap\",\n    tapZone: 4,           // retroflex (postalveolar/palatal)\n    tapDuration: 0.025,\n    tapGain: 0.5,\n    duration: 0.05,\n    voiced: true\n  },\n  \"ɺ\": {\n    symbol: \"ɺ\",\n    type: \"tap\",\n    tapZone: 2,           // lateral tap, still alveolar-ish\n    tapDuration: 0.025,\n    tapGain: 0.5,\n    duration: 0.05,\n    voiced: true,\n    tractLeft: [1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5],\n    tractRight: [1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5],\n  },\n\n  // Trills\n  \"r\": {\n    symbol: \"r\",\n    type: \"trill\",\n    trillZone: 2,         // alveolar\n    trillCycles: 4,       // typical for [r]\n    trillRate: 28,        // Hz (cycles per second)\n    trillGain: 1.0,\n    duration: 0.12,       // total trill duration (seconds)\n    voiced: true\n  },\n  \"ʙ\": {\n    symbol: \"ʙ\",\n    type: \"trill\",\n    trillZone: 0,         // bilabial\n    trillCycles: 3,\n    trillRate: 20,\n    trillGain: 1.0,\n    duration: 0.15,\n    voiced: true\n  },\n  \"ʀ\": {\n    symbol: \"ʀ\",\n    type: \"trill\",\n    trillZone: 6,         // uvular\n    trillCycles: 3,\n    trillRate: 22,\n    trillGain: 1.0,\n    duration: 0.13,\n    voiced: true\n  }\n\n};\n\n\n//# sourceURL=webpack://crowcrow/./src/state/phonemeMap.js?");

/***/ }),

/***/ "./src/state/wordPhonemeMap.js":
/*!*************************************!*\
  !*** ./src/state/wordPhonemeMap.js ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   wordPhonemeMap: () => (/* binding */ wordPhonemeMap)\n/* harmony export */ });\nconst wordPhonemeMap = {\n  // CVC words\n  \"cat\": \"k a t\",\n  \"dog\": \"d a g\",\n  \"man\": \"m a n\",\n  \"lid\": \"l i d\",\n  \"kid\": \"k i d\",\n  \"big\": \"b i g\",\n  \"dig\": \"d i g\",\n  \"pan\": \"p a n\",\n  \"fan\": \"f a n\",\n  \"van\": \"v a n\",\n  \"sin\": \"s i n\",\n  \"sun\": \"s a n\",\n  // CCV or VCC\n  \"sing\": \"s i ng\",\n  \"run\": \"r a n\",\n  \"win\": \"w i n\",\n  \"zip\": \"z i p\",\n  \"ship\": \"sh i p\",\n  \"chin\": \"tʃ i n\",\n  \"jam\": \"dʒ a m\",\n  \"lap\": \"l a p\",\n  \"mat\": \"m a t\",\n  \"nap\": \"n a p\",\n  \"bag\": \"b a g\",\n  \"tap\": \"t a p\",\n  \"zap\": \"z a p\"\n};\n\n//# sourceURL=webpack://crowcrow/./src/state/wordPhonemeMap.js?");

/***/ }),

/***/ "./src/ui/oscilloscope.js":
/*!********************************!*\
  !*** ./src/ui/oscilloscope.js ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   drawOscilloscope: () => (/* binding */ drawOscilloscope)\n/* harmony export */ });\nfunction drawOscilloscope(analyserNode) {\n    const canvas = document.getElementById('oscilloscope');\n    const canvasCtx = canvas.getContext('2d');\n    const bufferLength = analyserNode.fftSize;\n    const dataArray = new Uint8Array(bufferLength);\n    let animationId = null;\n  \n    function draw() {\n      animationId = requestAnimationFrame(draw);\n  \n      analyserNode.getByteTimeDomainData(dataArray);\n  \n      canvas.width = canvas.clientWidth;\n      canvas.height = canvas.clientHeight;\n  \n      // canvasCtx.fillStyle = '#343a40';\n      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);\n  \n      canvasCtx.lineWidth = 1;\n      canvasCtx.strokeStyle = '#fff';\n      canvasCtx.beginPath();\n  \n      const sliceWidth = canvas.width / bufferLength;\n      let x = 0;\n  \n      for (let i = 0; i < bufferLength; i++) {\n        const v = dataArray[i] / 128.0;\n        const y = (v * canvas.height) / 2;\n        i === 0 ? canvasCtx.moveTo(x, y) : canvasCtx.lineTo(x, y);\n        x += sliceWidth;\n      }\n  \n      canvasCtx.lineTo(canvas.width, canvas.height / 2);\n      canvasCtx.stroke();\n    }\n  \n    draw();\n  \n    return () => {\n      if (animationId) {\n        cancelAnimationFrame(animationId);\n      }\n    };\n  }\n\n//# sourceURL=webpack://crowcrow/./src/ui/oscilloscope.js?");

/***/ }),

/***/ "./src/ui/parameterPanel.js":
/*!**********************************!*\
  !*** ./src/ui/parameterPanel.js ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   renderParameterList: () => (/* binding */ renderParameterList),\n/* harmony export */   updateParameterDisplay: () => (/* binding */ updateParameterDisplay)\n/* harmony export */ });\nfunction renderParameterList(glottisParameterDescriptors, subglottalParameterDescriptors, tractParameterDescriptors) {\n  const paramList = document.getElementById('parameter-list');\n  if (!paramList) return;\n\n  const allParams = [\n    ...glottisParameterDescriptors,\n    ...subglottalParameterDescriptors,\n    ...tractParameterDescriptors,\n    { name: 'masterGain', defaultValue: 1 }\n  ];\n\n  paramList.innerHTML = allParams.map(desc =>\n    `<li><strong>${desc.name}</strong>: <span id=\"param-${desc.name}\">${desc.defaultValue}</span></li>`\n  ).join('');\n}\n\nfunction updateParameterDisplay(name, value) {\n  const el = document.getElementById(`param-${name}`);\n  if (el) el.textContent = value;\n}\n\n\n\n//# sourceURL=webpack://crowcrow/./src/ui/parameterPanel.js?");

/***/ }),

/***/ "./src/ui/phonemeButtonHelpers.js":
/*!****************************************!*\
  !*** ./src/ui/phonemeButtonHelpers.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getEffectiveGlideDuration: () => (/* binding */ getEffectiveGlideDuration),\n/* harmony export */   setFricativeNoiseParams: () => (/* binding */ setFricativeNoiseParams),\n/* harmony export */   setGlottalStop: () => (/* binding */ setGlottalStop),\n/* harmony export */   setLateralControl: () => (/* binding */ setLateralControl),\n/* harmony export */   setNasalOralControl: () => (/* binding */ setNasalOralControl),\n/* harmony export */   setNoiseFilterParams: () => (/* binding */ setNoiseFilterParams),\n/* harmony export */   setNoiseParams: () => (/* binding */ setNoiseParams),\n/* harmony export */   setPlosiveBurst: () => (/* binding */ setPlosiveBurst),\n/* harmony export */   setRhoticControl: () => (/* binding */ setRhoticControl),\n/* harmony export */   setVoicedGating: () => (/* binding */ setVoicedGating)\n/* harmony export */ });\nfunction setNoiseParams(phoneme, noiseNode, noiseTypeMap, audioContext) {\n  if (noiseNode) {\n    const noiseTypeValue = noiseTypeMap[phoneme.noiseType] ?? noiseTypeMap.simplex;\n    noiseNode.parameters.get('noiseType').setValueAtTime(noiseTypeValue, audioContext.currentTime);\n  }\n}\n\nfunction setNoiseFilterParams(phoneme, noiseFilterNode, audioContext) {\n  if (noiseFilterNode && phoneme.filterType) {\n    noiseFilterNode.type = phoneme.filterType;\n    noiseFilterNode.frequency.setValueAtTime(phoneme.filterFrequency ?? 1000, audioContext.currentTime);\n    noiseFilterNode.Q.setValueAtTime(phoneme.filterQ ?? 1, audioContext.currentTime);\n  } else if (noiseFilterNode) {\n    noiseFilterNode.type = 'allpass';\n    noiseFilterNode.frequency.setValueAtTime(1000, audioContext.currentTime);\n    noiseFilterNode.Q.setValueAtTime(1, audioContext.currentTime);\n  }\n}\n\nfunction setGlottalStop(phoneme, glottisNode, audioContext) {\n  if (glottisNode && phoneme.hasOwnProperty('glottalClosure')) {\n    glottisNode.parameters.get('glottalClosure').setValueAtTime(phoneme.glottalClosure, audioContext.currentTime);\n  } else if (glottisNode) {\n    glottisNode.parameters.get('glottalClosure').setValueAtTime(0, audioContext.currentTime);\n  }\n}\n\nfunction setVoicedGating(phoneme, glottisNode, audioContext, updateVoicedIndicator) {\n  if (glottisNode && phoneme.hasOwnProperty('voiced')) {\n    glottisNode.parameters.get('voiced').setValueAtTime(phoneme.voiced ? 1 : 0, audioContext.currentTime);\n    updateVoicedIndicator(phoneme.voiced);\n  }\n}\n\nfunction setNasalOralControl(phoneme, nasalNode, tractNode, audioContext) {\n  if (phoneme.isNasal) {\n    if (nasalNode) {\n      nasalNode.parameters.get('nasalCoupling').setValueAtTime(phoneme.nasalCoupling ?? 1.0, audioContext.currentTime);\n    }\n    if (tractNode) {\n      tractNode.parameters.get('oralClosureZone').setValueAtTime(phoneme.oralClosureZone ?? -1, audioContext.currentTime);\n    }\n  } else {\n    if (nasalNode) {\n      nasalNode.parameters.get('nasalCoupling').setValueAtTime(0, audioContext.currentTime);\n    }\n    if (tractNode) {\n      tractNode.parameters.get('oralClosureZone').setValueAtTime(\n        phoneme.oralClosureZone !== undefined ? phoneme.oralClosureZone : -1,\n        audioContext.currentTime\n      );\n    }\n  }\n}\n\nfunction setLateralControl(phoneme, tractNode, audioContext) {\n  if (tractNode && tractNode.parameters.has('isLateral')) {\n    tractNode.parameters.get('isLateral').setValueAtTime(phoneme.isLateral ? 1 : 0, audioContext.currentTime);\n    console.log(`Setting lateral control for phoneme to ${phoneme.isLateral ? 'lateral' : 'non-lateral'}`);\n  }\n}\n\nfunction setRhoticControl(phoneme, tractNode, audioContext) {\n  if (tractNode && tractNode.parameters.has('isRhotic')) {\n    tractNode.parameters.get('isRhotic').setValueAtTime(phoneme.isRhotic ? 1 : 0, audioContext.currentTime);\n    console.log(`Setting rhotic control for phoneme to ${phoneme.isRhotic ? 'rhotic' : 'non-rhotic'}`);\n  }\n}\n\nfunction setPlosiveBurst(phoneme, transientNode) {\n  if (phoneme.type === 'plosive' && transientNode) {\n    transientNode.port.postMessage({\n      type: 'burst',\n      noiseInjectionZone: phoneme.noiseInjectionZone,\n      duration: phoneme.burstDuration,\n      sharpness: phoneme.burstSharpness,\n      gain: phoneme.burstGain\n    });\n    console.log(`Triggering plosive burst for phoneme with noiseInjectionZone ${phoneme.noiseInjectionZone}, duration ${phoneme.burstDuration}, sharpness ${phoneme.burstSharpness}, gain ${phoneme.burstGain}`);\n  }\n}\n\nfunction setFricativeNoiseParams(phoneme, tractNode, currentIntensity, audioContext) {\n  if (phoneme.type === 'fricative' && tractNode) {\n    tractNode.parameters.get('noiseInjectionZone').setValueAtTime(phoneme.noiseInjectionZone ?? -1, audioContext.currentTime);\n    const modulatedEffort = (phoneme.effort ?? 0) * (currentIntensity ?? 1);\n    tractNode.parameters.get('fricativeEffort').setValueAtTime(modulatedEffort, audioContext.currentTime);\n  } else if (tractNode) {\n    tractNode.parameters.get('noiseInjectionZone').setValueAtTime(-1, audioContext.currentTime);\n    tractNode.parameters.get('fricativeEffort').setValueAtTime(0, audioContext.currentTime);\n  }\n}\n\nfunction getEffectiveGlideDuration(phoneme, globalGlide) {\n  return (phoneme && typeof phoneme.glideDuration === 'number') ? phoneme.glideDuration : globalGlide;\n}\n\n\n\n\n//# sourceURL=webpack://crowcrow/./src/ui/phonemeButtonHelpers.js?");

/***/ }),

/***/ "./src/ui/phonemeTypeHandlers.js":
/*!***************************************!*\
  !*** ./src/ui/phonemeTypeHandlers.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   handleClickPhoneme: () => (/* binding */ handleClickPhoneme),\n/* harmony export */   handleTapPhoneme: () => (/* binding */ handleTapPhoneme),\n/* harmony export */   handleTrillPhoneme: () => (/* binding */ handleTrillPhoneme)\n/* harmony export */ });\n/**\n * Handles click phonemes: sets tract shape, triggers click, animates tract.\n */\nfunction handleClickPhoneme(phoneme, id, context) {\n  const { tractNode, audioContext, clickNode, gateMasterGain, animateMasterGainSlider, drawTract, getTractLength } = context;\n\n  if (phoneme.tractLeft && phoneme.tractRight && tractNode && tractNode.parameters) {\n    for (let i = 0; i < 8; i++) {\n      const leftParam = tractNode.parameters.get(`tractLeft${i}`);\n      const rightParam = tractNode.parameters.get(`tractRight${i}`);\n      if (leftParam) leftParam.setValueAtTime(phoneme.tractLeft[i], audioContext.currentTime);\n      if (rightParam) rightParam.setValueAtTime(phoneme.tractRight[i], audioContext.currentTime);\n    }\n  }\n\n  if (clickNode) {\n    clickNode.parameters.get('clickType').setValueAtTime(phoneme.clickType || 0, audioContext.currentTime);\n    clickNode.parameters.get('burstZone').setValueAtTime(phoneme.burstZone || 1, audioContext.currentTime);\n    clickNode.parameters.get('burstDuration').setValueAtTime(phoneme.burstDuration || 0.018, audioContext.currentTime);\n    clickNode.parameters.get('burstSharpness').setValueAtTime(phoneme.burstSharpness || 0.95, audioContext.currentTime);\n    clickNode.parameters.get('burstGain').setValueAtTime(phoneme.burstGain || 1.2, audioContext.currentTime);\n    clickNode.parameters.get('trigger').setValueAtTime(1, audioContext.currentTime);\n    clickNode.parameters.get('trigger').setValueAtTime(0, audioContext.currentTime + 0.01);\n  }\n\n  if (phoneme.duration) {\n    gateMasterGain(phoneme.duration);\n    animateMasterGainSlider(phoneme.duration);\n  }\n\n  if (phoneme.burstZone !== undefined) {\n    const zones = Array(8).fill(0.5);\n    zones[phoneme.burstZone] = 1.0;\n    drawTract(zones, getTractLength());\n    setTimeout(() => {\n      zones[phoneme.burstZone] = 0.5;\n      drawTract(zones, getTractLength());\n    }, 80);\n  }\n}\n\n/**\n * Handles tap phonemes: sets tract shape, triggers tap, animates tract.\n */\nfunction handleTapPhoneme(phoneme, id, context) {\n  const { tractNode, audioContext, tapNode, gateMasterGain, animateMasterGainSlider, drawTract, getTractLength } = context;\n\n  if (phoneme.tractLeft && phoneme.tractRight && tractNode && tractNode.parameters) {\n    for (let i = 0; i < 8; i++) {\n      const leftParam = tractNode.parameters.get(`tractLeft${i}`);\n      const rightParam = tractNode.parameters.get(`tractRight${i}`);\n      if (leftParam) leftParam.setValueAtTime(phoneme.tractLeft[i], audioContext.currentTime);\n      if (rightParam) rightParam.setValueAtTime(phoneme.tractRight[i], audioContext.currentTime);\n    }\n  }\n\n  if (tapNode) {\n    tapNode.parameters.get('tapZone').setValueAtTime(phoneme.tapZone || 2, audioContext.currentTime);\n    tapNode.parameters.get('tapDuration').setValueAtTime(phoneme.tapDuration || 0.025, audioContext.currentTime);\n    tapNode.parameters.get('tapGain').setValueAtTime(phoneme.tapGain || 1.0, audioContext.currentTime);\n    tapNode.parameters.get('trigger').setValueAtTime(1, audioContext.currentTime);\n    tapNode.parameters.get('trigger').setValueAtTime(0, audioContext.currentTime + 0.01);\n  }\n\n  if (phoneme.duration) {\n    gateMasterGain(phoneme.duration);\n    animateMasterGainSlider(phoneme.duration);\n  }\n\n  if (phoneme.tapZone !== undefined) {\n    const zones = Array(8).fill(0.5);\n    zones[phoneme.tapZone] = 1.0;\n    drawTract(zones, getTractLength());\n    setTimeout(() => {\n      zones[phoneme.tapZone] = 0.5;\n      drawTract(zones, getTractLength());\n    }, 40);\n  }\n}\n\n/**\n * Handles trill phonemes: triggers trill, animates tract.\n */\nfunction handleTrillPhoneme(phoneme, id, context) {\n  const { trillNode, audioContext, gateMasterGain, animateMasterGainSlider, drawTract, getTractLength } = context;\n\n  if (trillNode) {\n    trillNode.parameters.get('trillZone').setValueAtTime(phoneme.trillZone || 2, audioContext.currentTime);\n    trillNode.parameters.get('trillCycles').setValueAtTime(phoneme.trillCycles || 3, audioContext.currentTime);\n    trillNode.parameters.get('trillRate').setValueAtTime(phoneme.trillRate || 20, audioContext.currentTime);\n    trillNode.parameters.get('trillGain').setValueAtTime(phoneme.trillGain || 1.0, audioContext.currentTime);\n    trillNode.parameters.get('trigger').setValueAtTime(1, audioContext.currentTime);\n    trillNode.parameters.get('trigger').setValueAtTime(0, audioContext.currentTime + 0.01);\n  }\n\n  if (phoneme.duration) {\n    gateMasterGain(phoneme.duration);\n    animateMasterGainSlider(phoneme.duration);\n  }\n\n  if (phoneme.trillZone !== undefined) {\n    const zones = Array(8).fill(0.5);\n    let cycle = 0;\n    const cycles = phoneme.trillCycles || 3;\n    const rate = phoneme.trillRate || 20;\n    const period = 1000 / rate;\n    function animateTrill() {\n      if (cycle >= cycles) return;\n      zones[phoneme.trillZone] = 1.0;\n      drawTract(zones, getTractLength());\n      setTimeout(() => {\n        zones[phoneme.trillZone] = 0.5;\n        drawTract(zones, getTractLength());\n        cycle++;\n        setTimeout(animateTrill, period);\n      }, period * 0.2);\n    }\n    animateTrill();\n  }\n}\n\n\n\n\n\n//# sourceURL=webpack://crowcrow/./src/ui/phonemeTypeHandlers.js?");

/***/ }),

/***/ "./src/ui/tractSliders.js":
/*!********************************!*\
  !*** ./src/ui/tractSliders.js ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getZoneValuesFromSliders: () => (/* binding */ getZoneValuesFromSliders),\n/* harmony export */   setSlidersFromZones: () => (/* binding */ setSlidersFromZones),\n/* harmony export */   setupTractSliders: () => (/* binding */ setupTractSliders)\n/* harmony export */ });\n/* harmony import */ var _tractViewer_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./tractViewer.js */ \"./src/ui/tractViewer.js\");\n/* harmony import */ var _parameterPanel_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./parameterPanel.js */ \"./src/ui/parameterPanel.js\");\n\n\n\n// Exported utility for use elsewhere\nfunction getZoneValuesFromSliders(tractSliders) {\n  return tractSliders.map(slider => parseFloat(slider.value));\n}\n\n// Utility to set all slider values from a zones array\nfunction setSlidersFromZones(tractSliders, zones) {\n  zones.forEach((value, i) => {\n    if (tractSliders[i]) tractSliders[i].value = value;\n  });\n}\n\n// Main setup function\nfunction setupTractSliders(tractNode, audioContext, tractSliders) {\n  tractSliders.forEach((slider, i) => {\n    slider.oninput = null;\n    slider.addEventListener('input', (e) => {\n      const value = parseFloat(e.target.value);\n\n      // Update tract visualization\n      (0,_tractViewer_js__WEBPACK_IMPORTED_MODULE_0__.drawTract)(getZoneValuesFromSliders(tractSliders));\n\n      // Update parameter panel\n      (0,_parameterPanel_js__WEBPACK_IMPORTED_MODULE_1__.updateParameterDisplay)(`zone${i}`, value.toFixed(2));\n\n      // --- NEW: Update the synth tract node if available ---\n      if (tractNode && tractNode.parameters) {\n        const param = tractNode.parameters.get(`zone${i}`);\n        if (param && audioContext) {\n          param.setValueAtTime(value, audioContext.currentTime);\n        }\n      }\n    });\n  });\n}\n\n//# sourceURL=webpack://crowcrow/./src/ui/tractSliders.js?");

/***/ }),

/***/ "./src/ui/tractViewer.js":
/*!*******************************!*\
  !*** ./src/ui/tractViewer.js ***!
  \*******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   drawTract: () => (/* binding */ drawTract)\n/* harmony export */ });\nfunction drawTract(zones, tractLength = 1.0) {\n  // Expect zones.length === 8\n  const canvas = document.getElementById('tract-visualizer');\n  if (!canvas) return;\n  const ctx = canvas.getContext('2d');\n\n  // Set canvas size\n  canvas.width = canvas.clientWidth;\n  canvas.height = canvas.clientHeight;\n\n  ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n  ctx.strokeStyle = '#fff';\n  ctx.lineWidth = 2;\n\n  const numZones = zones.length;\n  const centerX = canvas.width / 2;\n  // const totalHeight = canvas.height * 0.8; // leave some margin\n  const totalHeight = canvas.height * 0.8 * tractLength;\n  const baseY = (canvas.height - totalHeight) / 2;\n  // const spacing = totalHeight / (numZones - 1);\n  const spacing = totalHeight / (numZones - 1);\n\n  // Store left, right, and center points for profile lines\n  const leftPoints = [];\n  const rightPoints = [];\n  const centerPoints = [];\n  const ellipseTops = [];\n  const ellipseBottoms = [];\n\n  for (let i = 0; i < numZones; i++) {\n    const r = zones[i];\n    const radiusX = (r * canvas.width) / 4;\n    const radiusY = spacing / 3;\n    const y = baseY + i * spacing;\n\n    // Draw ellipse for each zone\n    ctx.beginPath();\n    ctx.ellipse(centerX, y, radiusX, radiusY, 0, 0, 2 * Math.PI);\n    ctx.stroke();\n\n    // Store left, right, and center points\n    leftPoints.push({ x: centerX - radiusX, y });\n    rightPoints.push({ x: centerX + radiusX, y });\n    centerPoints.push({ x: centerX, y });\n    ellipseTops.push({ x: centerX, y: y - radiusY });\n    ellipseBottoms.push({ x: centerX, y: y + radiusY });\n  }\n\n  // Draw left profile line\n  ctx.beginPath();\n  ctx.moveTo(leftPoints[0].x, leftPoints[0].y);\n  for (let i = 1; i < leftPoints.length; i++) {\n    ctx.lineTo(leftPoints[i].x, leftPoints[i].y);\n  }\n  ctx.stroke();\n\n  // Draw right profile line\n  ctx.beginPath();\n  ctx.moveTo(rightPoints[0].x, rightPoints[0].y);\n  for (let i = 1; i < rightPoints.length; i++) {\n    ctx.lineTo(rightPoints[i].x, rightPoints[i].y);\n  }\n  ctx.stroke();\n\n  // Draw center vertical line (from top of first ellipse to bottom of last)\n  ctx.beginPath();\n  ctx.moveTo(ellipseTops[0].x, ellipseTops[0].y);\n  ctx.lineTo(ellipseBottoms[ellipseBottoms.length - 1].x, ellipseBottoms[ellipseBottoms.length - 1].y);\n  ctx.stroke();\n}\n\n//# sourceURL=webpack://crowcrow/./src/ui/tractViewer.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/main.js");
/******/ 	
/******/ })()
;